# app 总结

添加全局context:
​	1.androidManifest.xml 重命名
​		<application
​			android:name="com.inuitive.sampleviewer.MyApplication"

	2.新创建类
		public class MyApplication extends Application {
	
		    private static Context context ;
	
		    public void onCreate(){
			context = getApplicationContext() ;
		    }
	
		    public static Context getContext(){
			return context ;
		    }
		}
	
	3.使用这个全局的context
		MyApplication.getContext() ;




加存储权限:

    private static final int REQUEST_EXTERNAL_STORAGE = 1;
    private static String[] PERMISSIONS_STORAGE = {
            "android.permission.READ_EXTERNAL_STORAGE",
            "android.permission.WRITE_EXTERNAL_STORAGE" };


    public static void verifyStoragePermissions(Activity activity) {
    
        try {
            //检测是否有写的权限
            int permission = ActivityCompat.checkSelfPermission(activity,
                    "android.permission.WRITE_EXTERNAL_STORAGE");
            if (permission != PackageManager.PERMISSION_GRANTED) {
                // 没有写的权限，去申请写的权限，会弹出对话框
                ActivityCompat.requestPermissions(activity, PERMISSIONS_STORAGE,REQUEST_EXTERNAL_STORAGE);
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }




异步消息线程:
​	1.案例一:随意的更新UI显示
​		1>在activity中创建handler
​			public class MainActivity extends ActionBarActivity {

				    	protected void onCreate(Bundle savedInstanceState) {
						
						        final Handler handler = new Handler() {
							    @Override
							    public void handleMessage(Message msg) {
								mStatus.setText((String) msg.obj);
								super.handleMessage(msg);
							    }
							};
	
							mSensor.setUIHandler(handler);
				
					}
			}


		 2>创建一个中间类
			public class Sensor {
	
				    private static Handler mHandler;
	
				    public static void setUIHandler(Handler handler) {
						mHandler = handler; /*保存这个handler*/
				    }
	
				    public static void showInfo(String text) {
					try {
					    Log.e("InuDevSample", text);
					    Message msg = mHandler.obtainMessage();
					    msg.obj = text;
					    mHandler.sendMessage(msg);
					} catch (Exception e) {
					    e.printStackTrace();
					}
				    }
			}


		3>在其他地方就可以随意更新UI了
			Sensor.showInfo("context");
	
		总结: 
			由于activity对象在被构造前,activity所在的线程已经执行了Looper.prepare()函数.即我们的activity中默认是存在消息队列的.
	
		案例二:实现异步消息线程
			
		            new Thread(new Runnable() {
		                @Override
		                public void run() {
	
		                    Looper.prepare();
	
				    final Handler handler1 = new Handler() {
							    @Override
							    public void handleMessage(Message msg) {
	
								super.handleMessage(msg);
							    }
							};
	
				    Looper.loop();/*这儿会不断去循环,不会出来的*/
	
		            }).start();



		            new Thread(new Runnable() {
		                @Override
		                public void run() {
		                    ...
					Message msg = handler1.obtainMessage();/*创建一个消息*/
					msg.obj = "111111";
					handler1.sendMessage(msg);/*向这个handler发送消息*/
		                }
		            }).start();
	
		总结:
			在构造handler对象前,必须已经执行过Looper.prepare(),但是prepare()不能被执行两次.
			创建handler对象可以在执行Looper.looper(),之前,之后都是可以的.
			Looper.prepare():为当前的线程创建 MessageQueue,一个线程 只能有一个MessageQueue.
			Looper.looper():不断的去循环去拿消息. 
				Message msg = queue.next();/*回调native方法 没有消息,此时会将该线程挂起*/
				msg.target.dispatchMessage(msg);/*msg.target类型 = Handler  回调到 -> handleMessage(){处理消息}*/


		案例三:定时器+异步消息线程
	
		1>在activity中创建handler
			public class MainActivity extends ActionBarActivity {
	
					    public Handler mWebHandler = new Handler() {
						public void handleMessage(Message msg) {
						    updateWebFrames();
						}
					    };
	
				    	    protected void onCreate(Bundle savedInstanceState) {
						
						                Timer frameWebConsumerTimer = new Timer();
								frameWebConsumerTimer.schedule(new TimerTask() {
								    @Override
								    public void run() {
									mWebHandler.obtainMessage(1).sendToTarget();
								    }
								}, 100, 10);
				
					    }
			}
	
		总结:
			1>activity中默认有 MessageQueue 和 Looper
			2>定时器在预定的时间里循环,进行回调(给MessageQueue发数据)
			3>在handleMessage处理更新画面的操作
	
		大总结:
			需要异步消息线程的地方:
				1>任务需要常驻,比如用于处理用户交互任务.
				2>任务需要根据外部传递的消息做不同的处理.





线程:
​                    new Thread(new Runnable() {
​                        @Override
​                        public void run() {
​                            ...
​                        }
​                    }).start();


反编译:
https://blog.csdn.net/FightLei/article/details/52432161?locationNum=6                                                                                                                  


		apktool b MyntaiService-arm_4.00.0009.87/ MyntaiService-arm_4.00.0009.87.apk
		keytool -genkey -v -alias KeyName -keyalg RSA -keysize 2048 -validity 10000 -keystore KeyFileName.keystore
		jarsigner -verbose -keystore KeyFileName.keystore InuService-arm_4.00.0009.87.apk KeyName




Toast使用:
​	    void toastMakeText(final String content){

			Handler handler = new Handler(Looper.getMainLooper());
	
			handler.post(new Runnable() {
			    @Override
			    public void run() {
				//放在UI线程弹Toast
				Toast.makeText(MyApplication.getContext(), content, Toast.LENGTH_LONG).show();/*MyApplication.getContext() 全局的*/
			    }
			});
	
	  }



点云转换:
​		    String pointData(int index, int d){

			int m = indexToY(index) ;/*m 图片中像素点的Y的坐标*/
			int n = indexToX(index) ;/*n 图片中像素点的y的坐标*/
			double pz ;/*世界坐标系的点*/
			double px ;
			double py ;
	
			pz = (double) d / mCameraFactor;
			px = (n - mCameraCx) * pz / mCameraFx;
			py = (m - mCameraCy) * pz / mCameraFy;
	
			return "" + px + " " + py + " " + pz + " 4294967295" + "\n";
		    }
	
		    int indexToX ( int index){
			return index % (Depth_W * 2);
		    }
	
		    int indexToY( int index){
			return index / (Depth_W * 2);
		    }



保存:
​		    void saveYUV(ByteBuffer frame) {
​			File dir;
​			File file = null;
​			String subdir = new String();
​			FileOutputStream outStream = null;
​			subdir = "/aaa/bYU";

			int capacity = frame.capacity();
			int limit = frame.limit();
	
			byte[] buffer = new byte[capacity];
			for (int offset = 0; offset < limit; offset++) {
			    buffer[offset] = frame.get(offset);
			}
			dir = new File(Environment.getExternalStorageDirectory() + subdir);   //     Environment.getExternalStorageDirectory()  = /storage/emulated/0
			if (!dir.exists()) {
			    dir.mkdirs();
			}
	
			try {
			    file = new File(dir.getCanonicalPath() + "/yuyv" + timeSigned() + ".yuv");
			} catch (Exception e) {
			    e.getMessage();
			}
	
			try {
			    outStream = new FileOutputStream(file);
			    outStream.write(buffer);
			    outStream.flush();
			    outStream.close();
			} catch (IOException e) {
			    e.printStackTrace();
			}
	
			toastMakeText("Save successful ! " + file.getName());
		    }




		    String timeSigned() {
	
			Calendar CD = Calendar.getInstance();
			int YY = CD.get(Calendar.YEAR);
			int MM = CD.get(Calendar.MONTH) + 1;
			int DD = CD.get(Calendar.DATE);
			int HH = CD.get(Calendar.HOUR_OF_DAY);
			int NN = CD.get(Calendar.MINUTE);
			int SS = CD.get(Calendar.SECOND);
			int MI = CD.get(Calendar.MILLISECOND);
	
			String ret = "" + YY
				+ String.format("%02d", MM)
				+ String.format("%02d", DD)
				+ String.format("%02d", HH)
				+ String.format("%02d", NN)
				+ String.format("%02d", SS)
				+ String.format("%04d", MI);
			return ret;
		    }




GRB和bitmap转换:

		public class RgbConversionBitmap {
	
		    /**
		     * @方法描述 将RGB字节数组转换成Bitmap，
		     */
		    static public Bitmap rgb2Bitmap(byte[] data, int width, int height) {
			int[] colors = convertByteToColor(data);    //取RGB值转换为int数组
			if (colors == null) {
			    return null;
			}
	
			Bitmap bmp = Bitmap.createBitmap(colors, 0, width, width, height,
				Bitmap.Config.ARGB_8888);
			return bmp;
		    }


		    // 将一个byte数转成int
		    // 实现这个函数的目的是为了将byte数当成无符号的变量去转化成int
		    public static int convertByteToInt(byte data) {
	
			int heightBit = (int) ((data >> 4) & 0x0F);
			int lowBit = (int) (0x0F & data);
			return heightBit * 16 + lowBit;
		    }


		    // 将纯RGB数据数组转化成int像素数组
		    public static int[] convertByteToColor(byte[] data) {
			int size = data.length;
			if (size == 0) {
			    return null;
			}
	
			int arg = 0;
			if (size % 3 != 0) {
			    arg = 1;
			}
	
			// 一般RGB字节数组的长度应该是3的倍数，
			// 不排除有特殊情况，多余的RGB数据用黑色0XFF000000填充
			int[] color = new int[size / 3 + arg];
			int red, green, blue;
			int colorLen = color.length;
			if (arg == 0) {
			    for (int i = 0; i < colorLen; ++i) {
				red = convertByteToInt(data[i * 3]);
				green = convertByteToInt(data[i * 3 + 1]);
				blue = convertByteToInt(data[i * 3 + 2]);
	
				// 获取RGB分量值通过按位或生成int的像素值
				color[i] = (red << 16) | (green << 8) | blue | 0xFF000000;
			    }
			} else {
			    for (int i = 0; i < colorLen - 1; ++i) {
				red = convertByteToInt(data[i * 3]);
				green = convertByteToInt(data[i * 3 + 1]);
				blue = convertByteToInt(data[i * 3 + 2]);
				color[i] = (red << 16) | (green << 8) | blue | 0xFF000000;
			    }
	
			    color[colorLen - 1] = 0xFF000000;
			}
	
			return color;
		    }
	
		    /**
		     * @方法描述 Bitmap转RGB
		     */
		    public static byte[] bitmap2RGB(Bitmap bitmap) {
			int bytes = bitmap.getByteCount();  //返回可用于储存此位图像素的最小字节数
	
			ByteBuffer buffer = ByteBuffer.allocate(bytes); //  使用allocate()静态方法创建字节缓冲区
			bitmap.copyPixelsToBuffer(buffer); // 将位图的像素复制到指定的缓冲区
	
			byte[] rgba = buffer.array();
			byte[] pixels = new byte[(rgba.length / 4) * 3];
	
			int count = rgba.length / 4;
	
			//Bitmap像素点的色彩通道排列顺序是RGBA
			for (int i = 0; i < count; i++) {
	
			    pixels[i * 3] = rgba[i * 4];        //R
			    pixels[i * 3 + 1] = rgba[i * 4 + 1];    //G
			    pixels[i * 3 + 2] = rgba[i * 4 + 2];       //B
	
			}
	
			return pixels;
		    }
	
		    /**
		     * @方法描述 Bitmap转RGB
		     */
		    public static byte[] getRGBFromBMP(Bitmap bmp) {
	
			int w = bmp.getWidth();
			int h = bmp.getHeight();
	
			byte[] pixels = new byte[w * h * 3]; // Allocate for RGB
	
			int k = 0;
	
			for (int x = 0; x < h; x++) {
			    for (int y = 0; y < w; y++) {
				int color = bmp.getPixel(y, x);
				pixels[k * 3] = (byte) Color.red(color);
				pixels[k * 3 + 1] = (byte) Color.green(color);
				pixels[k * 3 + 2] = (byte) Color.blue(color);
				k++;
			    }
			}
	
			return pixels;
		    }
		}



随意设置toast的显示时间:

		    void toastMakeText(final String content) {
	
			Handler handler = new Handler(Looper.getMainLooper());
	
			handler.post(new Runnable() {
			    @Override
			    public void run() {
				//放在UI线程弹Toast
				showMyToast(Toast.makeText(Myapplication.getContext(), content, Toast.LENGTH_LONG), 200);
			    }
			});
	
		    }



		    private void showMyToast(final Toast toast, final int cnt) {
			final Timer timer = new Timer();
			timer.schedule(new TimerTask() {
			    @Override
			    public void run() {
				toast.show();
			    }
			}, 0, 3000);
			new Timer().schedule(new TimerTask() {
			    @Override
			    public void run() {
				toast.cancel();
				timer.cancel();
			    }
			}, cnt);
		    }



Java和c之间数据共享:
​		
		Java代码:
		    ByteBuffer rgbByteBuffer = ByteBuffer.allocateDirect(mMaxRgbBufferSize);  /*必须是这个 allocateDirect 不然c 在找变量名的时候,返回一个空指针*/
	
		C代码:(不用传参,直接通过找变量的方式.而且传输效率高)
		    jclass cls = (*env).GetObjectClass(type);
		    jfieldID fid = (*env).GetFieldID(cls, "rgbByteBuffer", "Ljava/nio/ByteBuffer;");
		    jobject bar = (*env).GetObjectField(type, fid);
		    unsigned char *rgbBuffer = (unsigned char *) (*env).GetDirectBufferAddress(bar);
		    int size = (*env).GetDirectBufferCapacity(bar);
		    LOGI("size = %d", size);
	
		    if (NULL == rgbBuffer) {
			LOGI("NULL");
			return env->NewStringUTF("rgbByteBuffer = NULL");
		    }


体积测量:
#include <jni.h>
#include <string>
#include <android/log.h>
#include <opencv2/core/core.hpp>
#include <opencv2/opencv.hpp>

#define LOGI(...) ( (void) __android_log_print(ANDROID_LOG_INFO, "native-activity", __VA_ARGS__))
#define LOGW(...) ( (void) __android_log_print(ANDROID_LOG_WARN, "native-activity", __VA_ARGS__))

using namespace std;
using namespace cv;

void cvBoxPoints(CvBox2D box, CvPoint2D32f pt[4]) {
​    double angle = (-box.angle - 90) * CV_PI / 180;
​    float a = (float) cos(angle) * 0.5f;
​    float b = (float) sin(angle) * 0.5f;

    pt[0].x = box.center.x - a * box.size.height - b * box.size.width;
    pt[0].y = box.center.y + b * box.size.height - a * box.size.width;
    pt[1].x = box.center.x + a * box.size.height - b * box.size.width;
    pt[1].y = box.center.y - b * box.size.height - a * box.size.width;
    pt[2].x = 2 * box.center.x - pt[0].x;
    pt[2].y = 2 * box.center.y - pt[0].y;
    pt[3].x = 2 * box.center.x - pt[1].x;
    pt[3].y = 2 * box.center.y - pt[1].y;
}
//画出矩形框
void DrawBox(CvBox2D box, Mat img)
{
​    CvPoint2D32f point[4];
​    int i;


    for (i = 0; i<4; i++)
    {
        point[i].x = 0;
        point[i].y = 0;
    }
    cvBoxPoints(box, point); //计算二维盒子顶点
    CvPoint pt[4];
    for (i = 0; i<4; i++)
    {
        pt[i].x = (int)point[i].x;
        pt[i].y = (int)point[i].y;
    }
    line(img, pt[0], pt[1], CV_RGB(255, 255, 255), 2, 8, 0);
    line(img, pt[1], pt[2], CV_RGB(255, 255, 255), 2, 8, 0);
    line(img, pt[2], pt[3], CV_RGB(255, 255, 255), 2, 8, 0);
    line(img, pt[3], pt[0], CV_RGB(255, 255, 255), 2, 8, 0);
}


extern "C"
JNIEXPORT jstring JNICALL
Java_com_esp_uvc_usbcamera_CameraMainActivity_cube_1volume(JNIEnv *env, jobject type,
​                                                           jbyteArray yuyv_frame, jint yuyv_length,
​                                                           jintArray pixels_, jint w, jint h) {

    jclass cls = (*env).GetObjectClass(type);
    jfieldID fid = (*env).GetFieldID(cls, "rgbByteBuffer", "Ljava/nio/ByteBuffer;");
    jobject bar = (*env).GetObjectField(type, fid);
    unsigned char *rgbBuffer = (unsigned char *) (*env).GetDirectBufferAddress(bar);
    int size = (*env).GetDirectBufferCapacity(bar);
    LOGI("size = %d", size);
    
    if (NULL == rgbBuffer) {
        LOGI("NULL");
        return env->NewStringUTF("rgbByteBuffer = NULL");
    }
    
    jint *cbuf;
    jboolean ptfalse = false;
    
    cbuf = env->GetIntArrayElements(pixels_, &ptfalse);
    
    if (cbuf == NULL) {
        return 0;
    }
    
    jbyte *bbuf;
    bbuf = env->GetByteArrayElements(yuyv_frame, &ptfalse);
    
    unsigned char *yuyv = (unsigned char *) bbuf;
    Mat yuyv_siglechannle(h,w*2,CV_8UC1,yuyv);
    Rect rect(2 * w * 0.20, 0, 2 * w * 0.80, h);
    Mat yuyv_cut = yuyv_siglechannle(rect);
    
    string s_result;
    
    // Mat real_depth1(h, w * 2, CV_16UC1, cbuf);
    Mat real_depth1(h, w * 2, CV_16UC1);
    int kum = 0;
    for (int i = 0; i < h; i++) {
        for (int j = 0; j < 2 * w; j++) {
            real_depth1.at<ushort>(i, j) = ushort(cbuf[kum]);
            kum++;
        }
    }
    int Beishu = 5;
    int Yuzhi = 80;



    //去掉阴影区域
    Mat real_depth2 = real_depth1(rect);
    // blur(real_depth2,real_depth2,Size(5,5));
    Mat real_depth(h, w * 2 * 0.8, CV_16UC1);
    for (int i = 0; i < real_depth.rows; i++)
    {
        for (int j = 0; j < real_depth.cols; j++)
        {
            if (real_depth2.at<short>(i, j) > 2000)
            {
                real_depth2.at<short>(i, j) = 0;
                real_depth.at<short>(i, j) = 0;
            }
    
            else
                real_depth.at<short>(i, j) = real_depth2.at<short>(i, j) / Beishu;
        }
    }
    
    //计算地面深度值
    Mat nor_depth0;
    real_depth2.copyTo(nor_depth0);
    normalize(nor_depth0,nor_depth0,0,254,NORM_MINMAX);
    Mat nor_depth0_inv = 255 - nor_depth0;
    Mat nor_depth(h, w * 2 * 0.8, CV_8UC1);
    nor_depth0_inv.convertTo(nor_depth,CV_8UC1,1,0);
    Mat imggaussian;
    GaussianBlur(nor_depth,imggaussian,Size(5,5),0,0);
    Mat imgcanny0;
    Canny(imggaussian,imgcanny0,8,20);
    Mat imgDilate0;
    Mat element0 = getStructuringElement(MORPH_DILATE, Size(9, 9));
    dilate(imgcanny0,imgDilate0,element0);
    vector<vector<Point>> contours0;
    vector<Vec4i> hierarchy0;
    findContours(imgDilate0, contours0, hierarchy0, RETR_LIST, CV_CHAIN_APPROX_SIMPLE);
    if (contours0.size() == 0) {
        s_result = "0,0,0,0,0,0,0,0,0,0,0,0";
        env->ReleaseIntArrayElements(pixels_, cbuf, 0);
        env->ReleaseByteArrayElements(yuyv_frame, bbuf, 0);
    
        return env->NewStringUTF(s_result.c_str());
    }
    for(int i = 0; i<contours0.size(); i++){
        drawContours(nor_depth, contours0, i, cv::Scalar::all(255), CV_FILLED);
    }
    Mat imgthreold;
    threshold(nor_depth, imgthreold, 254, 255, THRESH_BINARY);
    double sum_1 = 0;
    int count_1 = 0;
    for(int i = 0 ; i<real_depth2.rows;i++)
    {
        for(int j = 0; j<real_depth2.cols;j++)
        {
            if(imgthreold.at<uchar>(i,j) == 0 && real_depth2.at<short>(i,j) != 0)
            {
                sum_1 += double(real_depth2.at<short>(i,j));
                count_1++;
            }
        }
    }
    double bottom_depth_0 = sum_1 / count_1;
    //地面深度计算完毕




    double minVal; double maxVal; Point minLoc; Point maxLoc;
    minMaxLoc(real_depth, &minVal, &maxVal, &minLoc, &maxLoc);
    
    int num_depth = int(maxVal) + 1;
    vector<int> depth_count = vector<int>(num_depth, 0);
    for (int i = 0; i < real_depth.rows; i++)
    {
        for (int j = 0; j < real_depth.cols; j++)
        {
            depth_count[real_depth.at<short>(i, j)] ++;
        }
    }
    vector<int> depth_count_copy(depth_count);
    
    sort(depth_count_copy.begin(), depth_count_copy.end());
    
    vector<int>::iterator biggest_one = find(depth_count.begin(), depth_count.end(), depth_count_copy[depth_count_copy.size() - 1]);
    int biggest_one_num = biggest_one - depth_count.begin();
    int next_one_num;
    for (int i = 2; i < depth_count_copy.size(); i++)
    {
        vector<int>::iterator next_one = find(depth_count.begin(), depth_count.end(), depth_count_copy[depth_count_copy.size() - i]);
        next_one_num = next_one - depth_count.begin();
        if (abs(biggest_one_num - next_one_num) > (Yuzhi / Beishu) && next_one_num != 0) break;
    }
    if (biggest_one_num < next_one_num) swap(biggest_one_num, next_one_num);
    // cout << "count1: " << biggest_one_num << "count2: " << next_one_num << endl;
    
    double top_depth_sum = 0;int top_count = 0;
    double bottom_depth_sum = 0;int bottom_count = 0;
    Mat gray_depth(h,w*2*0.80,  CV_8UC1);
    for (int i = 0; i < gray_depth.rows; i++)
    {
        for (int j = 0; j < gray_depth.cols; j++)
        {
            if (real_depth.at<short>(i, j) < (next_one_num + (biggest_one_num - next_one_num)/2)
                && real_depth.at<short>(i, j) > (next_one_num - (biggest_one_num - next_one_num)/2))
            {
                if(real_depth2.at<short>(i, j) != 0)
                {
                    top_depth_sum += double(real_depth2.at<short>(i, j));
                    top_count++ ;
                    gray_depth.at<uchar>(i, j) = 255;
                    continue;
                }
            }

//            else if (real_depth.at<short>(i, j) < (biggest_one_num + Yuzhi/(2* Beishu))
//                     && real_depth.at<short>(i, j) > (biggest_one_num - Yuzhi/(2* Beishu)))
//            {
//
//                if(real_depth2.at<short>(i, j) != 0)
//                {
//                    bottom_depth_sum += double(real_depth2.at<short>(i, j));
//                    bottom_count++;
//                    gray_depth.at<uchar>(i, j) = 0;
//                    continue;
//                }
//            }
​            else
​                gray_depth.at<uchar>(i, j) = 0;
​        }
​    }

    double bottom_depth =0;
    double top_depth = 0;
    bottom_depth = bottom_count>0? bottom_depth_sum/bottom_count : 0;
    top_depth = top_count>0? top_depth_sum/top_count : 0;
    
    Mat img_draw(h,w*2*0.8,CV_8UC1,Scalar(0));
    Mat imgcanny;
    
    Canny(gray_depth, imgcanny, 50, 150, 3);
    
    Mat imgDilate;
    Mat element = getStructuringElement(MORPH_DILATE, Size(5, 5));
    dilate(imgcanny, imgDilate, element);
    
    //轮廓识别与描绘
    //std::vector<std::vector<cv::Point>> contours;
    vector<vector<Point>> contours;
    vector<Vec4i> hierarchy;
    //轮廓内面积
    vector<double> interArea;
    
    //反二值化后，得到白色区域的黑色轮廓
    findContours(imgDilate, contours, hierarchy, RETR_LIST, CV_CHAIN_APPROX_SIMPLE);
    if (contours.size() == 0) {
        s_result = "0,0,0,0,0,0,0,0,0,0,0,0";
        env->ReleaseIntArrayElements(pixels_, cbuf, 0);
        env->ReleaseByteArrayElements(yuyv_frame, bbuf, 0);
        return env->NewStringUTF(s_result.c_str());
    }
    for (int i = 0; i < contours.size(); i++)
    {
        interArea.push_back(contourArea(contours[i]));
    }
    
    vector<double> interAreaTem = interArea;
    sort(interAreaTem.begin(), interAreaTem.end());
    double areabiggest = interAreaTem[interAreaTem.size() - 1];
    
    vector<double>::iterator biggest_contours = find(interArea.begin(), interArea.end(), areabiggest);
    int contours_num = biggest_contours - interArea.begin();
    
    drawContours(img_draw, contours, contours_num, cv::Scalar::all(255), CV_FILLED);
    
    //获取所需轮廓外接矩形
    CvBox2D box = minAreaRect(contours[contours_num]);


    //box.size.height = box.size.height / (box.size.height * box.size.width / areabiggest);
    //box.size.width = box.size.width / (box.size.height * box.size.width / areabiggest);
    
            //    double top_depth_sum0 = 0; int top_count0 = 0;
            //    for(int i = 5; i < img_draw.rows; i++)
            //    {
            //        for(int j = 5; j < img_draw.cols; j++)
            //        {
            //            if(img_draw.at<uchar>(i,j) > 0 && img_draw.at<uchar>(i-5,j-5) > 0 &&img_draw.at<uchar>(i+5,j+5) > 0)
            //            {
            //                if(real_depth2.at<short>(i, j) != 0)
            //                {
            //                    top_depth_sum0 += double(real_depth2.at<short>(i, j));
            //                    top_count0++ ;
            //                }
            //            }
            //        }
            //    }
            //
            //    double top_depth_0 = top_depth_sum0/top_count0;
    
    //得到盒子四个顶点的八个数据
    CvPoint2D32f point[4];
    for (int i = 0; i < 4; i++) {
        point[i].x = 0;
        point[i].y = 0;
    }
    cvBoxPoints(box, point); //计算二维盒子顶点
    DrawBox(box,yuyv_cut);
    int yuyv_i = 0;
//    for (int i = 0; i < h; i++) {
//        for(int j = 0; j < 2*w * 0.2; j++)
//        {
//            rgbBuffer[yuyv_i++] = 0; rgbBuffer[yuyv_i++] = 0; rgbBuffer[yuyv_i++] = 0;
//        }
//        for(int j = 2*w * 0.2; j < 2*w; j++)
//        {
//            rgbBuffer[yuyv_i++] = yuyv_cut.at<uchar>(i,j-2*w*0.2);
//            rgbBuffer[yuyv_i++] = 0; rgbBuffer[yuyv_i++] = 0;
//            //LOGI("value:  %d",rgbBuffer[yuyv_i]);
//        }
//    }



    double height = abs(bottom_depth_0 - top_depth) ;
    double depth_top = top_depth ;
    
    double pra;
    double pra0;
    if (h == 480)
        //pra0 = 0.7558;
        pra0 = 0.740;
    else
        //pra0 = 0.8660;
        pra0 = 0.848;
    pra = pra0 * double(sqrt(double(1) / double(h * 2 * w)));
    
    box.size.width = pra * box.size.width * depth_top;
    box.size.height = pra * box.size.height * depth_top;
    double cube[4];
    cube[0] = box.size.width > box.size.height ? box.size.width : box.size.height;
    //cube[0] = box.size.width;
    //cube[1] = box.size.height;
    cube[1] = box.size.width > box.size.height ? box.size.height : box.size.width;
    //cube[1] = box.size.height;
    cube[2] = height;
    cube[3] = box.size.width * box.size.height * height;
    
    int cube_int[12];
    cube_int[0] = int(cube[0]);
    cube_int[1] = int(cube[1]);
    cube_int[2] = int(cube[2]);
    cube_int[3] = int(cube[3]);


    int num_point = 4;
    for (int i = 0; i < 4; i++) {
        cube_int[num_point++] = (int) point[i].x + 2*w * 0.2;
        cube_int[num_point++] = (int) point[i].y;
    }
    
    //最后需要根据实际深度将实际长度和宽度采集出来
    s_result = to_string(cube_int[0] / 10) + "." + to_string(cube_int[0] % 10) +
               "," + to_string(cube_int[1] / 10) + "." + to_string(cube_int[1] % 10) +
               "," + to_string(cube_int[2] / 10) + "." + to_string(cube_int[2] % 10) +
               "," + to_string(cube_int[3] / 1000) + "." + to_string(cube_int[3] % 1000);
    
    for (int k = 4; k < 12; k++) {
        s_result = s_result + "," + to_string(cube_int[k]);
    }
    
    // s_result = to_string(contours.size());
    //s_result = "one: "+to_string(count[0]) + "two: "+ to_string(count[1]) + "third: "+ to_string(count[2]);
    env->ReleaseIntArrayElements(pixels_, cbuf, 0);
    env->ReleaseByteArrayElements(yuyv_frame, bbuf, 0);
    return env->NewStringUTF(s_result.c_str());
}




activity 方向:
​		if (mLandscape) {
​		    if (mReverse) {
​		        setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE);/*希望Activity在横向屏幕上显示，但与正常的横向屏幕方向相反*/
​		    } else {
​		        setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE);/*希望Activity在横向屏上显示，也就是说横向的宽度要大于纵向的高度，并且忽略方向传感器的影响。*/
​		    }
​		} else {
​		    if (mReverse) {
​		        setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT);/*希望Activity在纵向屏幕上显示，但与正常的纵向屏幕方向相反*/
​		    } else {
​		        setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_PORTRAIT);/*希望Activity在纵向屏上显示，也就是说纵向的高度要大于横向的宽度，并且忽略方向传感器的影响。*/
​		    }
​		}


		if (mFlip) {
			    mUVCCameraViewL.setScaleX(-1);/*按照x轴进行缩放*/
			    mUVCCameraViewR.setScaleX(-1);
			} else {
			    mUVCCameraViewL.setScaleX(1);
			    mUVCCameraViewR.setScaleX(1);
			}


动态调整,控件在相对布局中的位置:

		    private TextView mVolumeRecovery = null;
	
		    void adjustDepthFrame() {
	
			byte resoult = 0b00000000;
			if (mFlip) resoult |= 0b00000001;
			if (mLandscape) resoult |= 0b00000010;
			if (mReverse) resoult |= 0b00000100;
	
			RelativeLayout.LayoutParams params = (RelativeLayout.LayoutParams) mVolumeRecovery.getLayoutParams();
	
			switch (resoult) {
			    case 0b00000111:
				Log.i(TAG, "adjustDepthFrame: x轴镜像 横屏 反方向 阴影设置");
				params.addRule(RelativeLayout.ALIGN_PARENT_RIGHT);
				break;
			    case 0b00000110:
				Log.i(TAG, "adjustDepthFrame: 横屏 反方向");
				params.addRule(RelativeLayout.ALIGN_LEFT);
				break;
			    case 0b00000101:
				Log.i(TAG, "adjustDepthFrame: x轴镜像  反方向 阴影设置");
				params.addRule(RelativeLayout.ALIGN_PARENT_RIGHT);
				break;
			    case 0b00000100:
				Log.i(TAG, "adjustDepthFrame: 反方向");
				params.addRule(RelativeLayout.ALIGN_LEFT);
				break;
			    case 0b00000011:
				Log.i(TAG, "adjustDepthFrame: x轴镜像 横屏 阴影设置");
				params.addRule(RelativeLayout.ALIGN_PARENT_RIGHT);
				break;
			    case 0b00000010:
				Log.i(TAG, "adjustDepthFrame: 横屏");
				params.addRule(RelativeLayout.ALIGN_LEFT);
				break;
			    case 0b00000000:
				Log.i(TAG, "adjustDepthFrame: 正常 阴影IR");
				params.addRule(RelativeLayout.ALIGN_LEFT);
				break;
			    case 0b00000001:
				Log.i(TAG, "adjustDepthFrame: x轴镜像 阴影设置");
				params.addRule(RelativeLayout.ALIGN_PARENT_RIGHT);
				break;
			    default:
				break;
			}
	
			params.setMargins(5, 5, 5, 5);/*调整控件和布局之间的距离*/
			mVolumeRecovery.setLayoutParams(params); //使layout更新
			mVolumeRecovery.setVisibility(View.INVISIBLE);
		    }




画图:

	布局xml:
		    <SurfaceView
		        android:id="@+id/volumeSurfaceViewFrame"
		        android:layout_width="wrap_content"
		        android:layout_height="wrap_content"
		        android:src="@drawable/border"
		        android:layout_alignTop="@+id/camera_view_R"
		        android:layout_alignBottom="@+id/camera_view_R"
		        android:layout_alignLeft="@+id/camera_view_R"
		        android:layout_alignRight="@+id/camera_view_R"/>
	
			private SurfaceView mVolumeSurfaceView = null;
			    private SurfaceView mVolumeSurfaceViewFrame = null;
			    private SurfaceHolder mVolumeSurfaceHolder = null;
			    private SurfaceHolder mVolumeSurfaceHolderFrame = null;
	
			try {
			    mVolumeSurfaceView = findViewById(R.id.volumeSurfaceView);
			    mVolumeSurfaceHolder = mVolumeSurfaceView.getHolder();
	
			    mVolumeSurfaceView.setZOrderOnTop(true);//处于顶层
			    mVolumeSurfaceHolder.setFormat(PixelFormat.TRANSPARENT);//设置surface为透明
			    volumeDrawing = new VolumeDrawing(mVolumeSurfaceHolder, mVolumeSurfaceView);
			    volumeDrawingREAL = true;
	
			} catch (Exception e) {
			    Log.i(TAG, "initAll: e = " + e.getMessage());
			}



			package com.esp.uvc.usbcamera;
	
			import android.graphics.Bitmap;
			import android.graphics.Canvas;
			import android.graphics.Color;
			import android.graphics.Paint;
			import android.graphics.PorterDuff;
			import android.util.Log;
			import android.view.SurfaceHolder;
			import android.view.SurfaceView;
	
			/**
			 * Created by colbycao on 18-7-16.
			 */
	
			public class VolumeDrawing {
	
			    private Paint mRedPaint = null;
			    private Paint mBluePaint = null;
			    private Canvas canvas = null;
			    private boolean canvasBoolean = false;
			    private SurfaceHolder mVolumeSurfaceHolder = null;
			    private SurfaceView mVolumeSurfaceView = null;
			    private final String TAG = "VolumeDrawing";
			    private int depthW = 0;
			    private int depthH = 0;
			    private final float ProPortion = (float) 1;
			    private final int EdgeX = 5;
			    private final int EdgeY = 5;
			    private final float EdgeRateOut = 10F;
			    private final float EdgeRateIn = 5F;
			    private final float EdgeRateOutLine = 5F;
			    private final float EdgeRateInLine = 10F;
			    private float OffsetX = -20F;
			    private boolean REAL = false;
	
			    VolumeDrawing(SurfaceHolder surfaceHolder, SurfaceView surfaceView) {
	
				mVolumeSurfaceView = surfaceView;
	
				mVolumeSurfaceHolder = surfaceHolder;
				//定义画笔
				mRedPaint = new Paint();
				mRedPaint.setColor(Color.RED);
				mRedPaint.setAntiAlias(true);//去锯齿
				mRedPaint.setStyle(Paint.Style.STROKE);//空心
				// 设置paint的外框宽度
				mRedPaint.setStrokeWidth(2f);
	
				//定义画笔
				mBluePaint = new Paint();
				mBluePaint.setColor(Color.YELLOW);
				mBluePaint.setAntiAlias(true);//去锯齿
				mBluePaint.setStyle(Paint.Style.STROKE);//空心
				// 设置paint的外框宽度
				mBluePaint.setStrokeWidth(5f);
				REAL = true;
			    }
	
			    void drawPoint(int[][] RectanglePoint, String volume, int w, int h, boolean mFlip) {
	
				if (REAL) {
				    depthH = h;
				    depthW = w;
	
				    canvas = mVolumeSurfaceHolder.lockCanvas();
				    canvasBoolean = true;
	
				    canvas.drawColor(Color.TRANSPARENT, PorterDuff.Mode.CLEAR); //清楚掉上一次的画框。
	
				    canvas.drawLine((float) getPixelX(RectanglePoint[0][0], mFlip), (float) getPixelY(RectanglePoint[0][1]), (float) getPixelX(RectanglePoint[1][0], mFlip), (float) getPixelY(RectanglePoint[1][1]), mBluePaint);
				    canvas.drawLine((float) getPixelX(RectanglePoint[1][0], mFlip), (float) getPixelY(RectanglePoint[1][1]), (float) getPixelX(RectanglePoint[2][0], mFlip), (float) getPixelY(RectanglePoint[2][1]), mBluePaint);
				    canvas.drawLine((float) getPixelX(RectanglePoint[2][0], mFlip), (float) getPixelY(RectanglePoint[2][1]), (float) getPixelX(RectanglePoint[3][0], mFlip), (float) getPixelY(RectanglePoint[3][1]), mBluePaint);
				    canvas.drawLine((float) getPixelX(RectanglePoint[3][0], mFlip), (float) getPixelY(RectanglePoint[3][1]), (float) getPixelX(RectanglePoint[0][0], mFlip), (float) getPixelY(RectanglePoint[0][1]), mBluePaint);
	
				    mVolumeSurfaceHolder.unlockCanvasAndPost(canvas);
				}
			    }
	
			    float[][] drawFrame(int w, int h, boolean mFlip) {
	
				if (REAL) {
				    float[][] outPoint = new float[4][2];
				    float[][] inPoint = new float[4][2];
	
				    depthH = h;
				    depthW = w;
	
				    if (720 == h) OffsetX = -40F;
				    if (mFlip) OffsetX = -OffsetX;
	
				/*
				* 01
				* 23
				* */
				    outPoint[0][0] = (float) (0 + depthW / EdgeRateOut + EdgeX - OffsetX);
				    outPoint[0][1] = (float) (0 + depthH / EdgeRateOut + EdgeY);
				    outPoint[1][0] = (float) (depthW - EdgeX - depthW / EdgeRateOut - OffsetX);
				    outPoint[1][1] = (float) (0 + depthH / EdgeRateOut + EdgeY);
				    outPoint[2][0] = (float) (0 + depthW / EdgeRateOut + EdgeX - OffsetX);
				    outPoint[2][1] = (float) (depthH - EdgeY - depthH / EdgeRateOut);
				    outPoint[3][0] = (float) (depthW - EdgeX - depthW / EdgeRateOut - OffsetX);
				    outPoint[3][1] = (float) (depthH - EdgeY - depthH / EdgeRateOut);
	
				    inPoint[0][0] = (float) (0 + depthW / EdgeRateIn + EdgeX - OffsetX);
				    inPoint[0][1] = (float) (0 + depthH / EdgeRateIn + EdgeY);
				    inPoint[1][0] = (float) (depthW - EdgeX - depthW / EdgeRateIn - OffsetX);
				    inPoint[1][1] = (float) (0 + depthH / EdgeRateIn + EdgeY);
				    inPoint[2][0] = (float) (0 + depthW / EdgeRateIn + EdgeX - OffsetX);
				    inPoint[2][1] = (float) (depthH - EdgeY - depthH / EdgeRateIn);
				    inPoint[3][0] = (float) (depthW - EdgeX - depthW / EdgeRateIn - OffsetX);
				    inPoint[3][1] = (float) (depthH - EdgeY - depthH / EdgeRateIn);
	
				    drawLine(outPoint, EdgeRateOutLine);
				    //drawLine(inPoint, EdgeRateInLine);
				    if (mFlip) OffsetX = -OffsetX;
				    return outPoint;
				}
	
				return new float[4][2];
			    }
	
			    void cleanDram() {
	
				if (canvasBoolean && REAL) {
				    canvas = mVolumeSurfaceHolder.lockCanvas();
				    canvas.drawColor(Color.TRANSPARENT, PorterDuff.Mode.CLEAR); //清楚掉上一次的画框。
				    canvasBoolean = false;
				    mVolumeSurfaceHolder.unlockCanvasAndPost(canvas);
				}
			    }
	
			    private float getPixelX(int x, boolean mFlip) {
	
				float depthX = (float) x / 2;
				if (mFlip) depthX = depthW - depthX;
				return depthX * ProPortion;
			    }
	
			    private float getPixelY(int y) {
	
				float depthY = (float) y;
				return depthY * ProPortion;
			    }
	
			    void drawGRB(byte rgb[], int w, int h) {
	
				if(REAL){
				    depthH = h;
				    depthW = w;
				    Bitmap bitmap = null;
				    RgbConversionBitmap rgbConversionBitmap = new RgbConversionBitmap();
	
				    canvas = mVolumeSurfaceHolder.lockCanvas();
				    canvasBoolean = true;
	
				    bitmap = rgbConversionBitmap.rgb2Bitmap(rgb, w, h);
				    canvas.drawBitmap(bitmap, 0, 0, mBluePaint);
	
				    mVolumeSurfaceHolder.unlockCanvasAndPost(canvas);
				}
			    }
	
			    private void drawLine(float[][] point, float rate) {
	
				canvas = mVolumeSurfaceHolder.lockCanvas();
				canvasBoolean = true;
	
				canvas.drawLine(point[0][0], point[0][1], point[0][0] + depthW / rate, point[0][1], mRedPaint);
				canvas.drawLine(point[1][0], point[1][1], point[1][0] - depthW / rate, point[1][1], mRedPaint);
	
				canvas.drawLine(point[1][0], point[1][1], point[1][0], point[1][1] + depthH / rate, mRedPaint);
	
				canvas.drawLine(point[3][0], point[3][1], point[3][0], point[3][1] - depthH / rate, mRedPaint);
	
				canvas.drawLine(point[3][0], point[3][1], point[3][0] - depthW / rate, point[3][1], mRedPaint);
	
				canvas.drawLine(point[2][0], point[2][1], point[2][0] + depthW / rate, point[2][1], mRedPaint);
	
				canvas.drawLine(point[2][0], point[2][1], point[2][0], point[2][1] - depthH / rate, mRedPaint);
	
				canvas.drawLine(point[0][0], point[0][1], point[0][0], point[0][1] + depthH / rate, mRedPaint);


				mVolumeSurfaceHolder.unlockCanvasAndPost(canvas);
			    }
	
			    void drawDepth(float[][] point, int value[]){
	
				if(REAL){
				    canvas = mVolumeSurfaceHolder.lockCanvas();
				    canvasBoolean = true;
				    //canvas.drawColor(Color.TRANSPARENT, PorterDuff.Mode.CLEAR); //清楚掉上一次的画框。
				    canvas.drawText("" + value[0],point[0][0], point[0][1], mRedPaint);
				    canvas.drawText("" + value[1],point[1][0], point[1][1], mRedPaint);
				    canvas.drawText("" + value[2],point[2][0], point[2][1], mRedPaint);
				    canvas.drawText("" + value[3],point[3][0], point[3][1], mRedPaint);
	
				    mVolumeSurfaceHolder.unlockCanvasAndPost(canvas);
				}
	
			    }
			}




gitignore:

		build
		.idea
		*.iml
		.externalNativeBuild
	
		*.dex
		*.bin
		*.class
	
		bin/
		gen/
		out/
		.gradle/
		build/


		local.properties
		proguard/
		.log
	
		captures/
	
		*.iml
	
		*.jks
	
		*.bin








增加权限:
/home/colbycao/slightech/code/low-layout/FireNow-Nougat/frameworks/base/data/etc/platform.xml










import android.app.Activity;
import android.content.pm.PackageManager;
import android.support.v4.app.ActivityCompat;
import android.support.v7.app.AppCompatActivity;
import android.os.Bundle;

public class MainActivity extends AppCompatActivity {

    private static final int REQUEST_EXTERNAL_STORAGE = 1;
    private static String[] PERMISSIONS_STORAGE = {
            "android.permission.READ_EXTERNAL_STORAGE",
            "android.permission.WRITE_EXTERNAL_STORAGE" };


//    public static void verifyStoragePermissions(Activity activity) {
//        try {
//            //检测是否有写的权限
//            int permission = ActivityCompat.checkSelfPermission(activity,
//                    "android.permission.WRITE_EXTERNAL_STORAGE");
//            if (permission != PackageManager.PERMISSION_GRANTED) {
//                // 没有写的权限，去申请写的权限，会弹出对话框
//                ActivityCompat.requestPermissions(activity, PERMISSIONS_STORAGE,REQUEST_EXTERNAL_STORAGE);
//            }
//        } catch (Exception e) {
//            e.printStackTrace();
//        }
//    }

    public static void verifyStoragePermissions(Activity activity) {
        try {
            //检测是否有写的权限
            int permission = ActivityCompat.checkSelfPermission(activity,
                    "android.permission.WRITE_EXTERNAL_STORAGE");
            if (permission != PackageManager.PERMISSION_GRANTED) {
                // 没有写的权限，去申请写的权限，会弹出对话框
                ActivityCompat.requestPermissions(activity, PERMISSIONS_STORAGE,REQUEST_EXTERNAL_STORAGE);
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
    
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
    
        verifyStoragePermissions(MainActivity.this);
    }
}